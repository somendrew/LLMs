{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWs6f8AUpdwxYjwa6YnsCX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somendrew/LLMs/blob/main/LLM1_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis\\\n",
        "Text Classification\\\n",
        "Summarization\\\n",
        "Chatbot"
      ],
      "metadata": {
        "id": "t0gyydCAIfV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggin Face Transformer Library"
      ],
      "metadata": {
        "id": "1QUruC2VuBPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Wxc9gH-runKW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zfTo0ts3tyh1"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis"
      ],
      "metadata": {
        "id": "eQzzoQU7wnuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(task=\"sentiment-analysis\")(\"Love This!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Iphlu8jdu-b3",
        "outputId": "272a13ce-e457-44b0-a801-015d08e4bc7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998745918273926}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(task =\"sentiment-analysis\",model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
      ],
      "metadata": {
        "id": "7P8hSLAywz40"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"Hate this!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5THgsHGyMyV",
        "outputId": "ab626358-bb93-4683-b020-775296b7fad1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9996519088745117}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"eww\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opqZ3Tz10ZFd",
        "outputId": "65a5ba4c-4da6-4f9e-ebf5-f6be68bbf022"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9806575179100037}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"What a jerk!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RrZR1ZF0b0R",
        "outputId": "c25fc8f2-cc48-47dd-a071-eb06c9ced0e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9991088509559631}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Sentimental Analysis at once using list"
      ],
      "metadata": {
        "id": "tpu0e6oS1B8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_list = [\"this is great\", \\\n",
        "             \"Thanks for nothing\",\\\n",
        "             \"may you dont wake up\",\\\n",
        "             \"sit on my face!\"]\n",
        "\n",
        "classifier(test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ygWe70v0mN1",
        "outputId": "1cff6310-645f-4f8c-80c7-884a26a0f6e6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998785257339478},\n",
              " {'label': 'POSITIVE', 'score': 0.9680058360099792},\n",
              " {'label': 'NEGATIVE', 'score': 0.9977160692214966},\n",
              " {'label': 'POSITIVE', 'score': 0.9969485402107239}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2 = pipeline(task =\"text-classification\",model=\"SamLowe/roberta-base-go_emotions\",top_k=None)"
      ],
      "metadata": {
        "id": "D2ZPYG0L1czf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2(test_list[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtvHFhIK3ApZ",
        "outputId": "c6bcb1ca-1e99-42d5-8cb9-a8a42faee0b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'neutral', 'score': 0.9514515995979309},\n",
              "  {'label': 'annoyance', 'score': 0.019070714712142944},\n",
              "  {'label': 'anger', 'score': 0.009620272554457188},\n",
              "  {'label': 'amusement', 'score': 0.0070619527250528336},\n",
              "  {'label': 'approval', 'score': 0.005688096396625042},\n",
              "  {'label': 'disgust', 'score': 0.005251647438853979},\n",
              "  {'label': 'realization', 'score': 0.003787725931033492},\n",
              "  {'label': 'disappointment', 'score': 0.003579547395929694},\n",
              "  {'label': 'sadness', 'score': 0.0033763302490115166},\n",
              "  {'label': 'fear', 'score': 0.0029731267131865025},\n",
              "  {'label': 'disapproval', 'score': 0.0028098684269934893},\n",
              "  {'label': 'excitement', 'score': 0.0023853678721934557},\n",
              "  {'label': 'curiosity', 'score': 0.00221509812399745},\n",
              "  {'label': 'joy', 'score': 0.0022025094367563725},\n",
              "  {'label': 'confusion', 'score': 0.0020974602084606886},\n",
              "  {'label': 'embarrassment', 'score': 0.001990321557968855},\n",
              "  {'label': 'surprise', 'score': 0.0017464219126850367},\n",
              "  {'label': 'admiration', 'score': 0.0017218801658600569},\n",
              "  {'label': 'caring', 'score': 0.001389048877172172},\n",
              "  {'label': 'optimism', 'score': 0.0012831295607611537},\n",
              "  {'label': 'desire', 'score': 0.0011934874346479774},\n",
              "  {'label': 'love', 'score': 0.0009618632611818612},\n",
              "  {'label': 'nervousness', 'score': 0.0006428199703805149},\n",
              "  {'label': 'grief', 'score': 0.0006209394196048379},\n",
              "  {'label': 'gratitude', 'score': 0.0006197979091666639},\n",
              "  {'label': 'remorse', 'score': 0.00048749061534181237},\n",
              "  {'label': 'pride', 'score': 0.00037945256917737424},\n",
              "  {'label': 'relief', 'score': 0.00034451851388439536}]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarization"
      ],
      "metadata": {
        "id": "8EmDcjq_IqRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\",model = \"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "3EPUItWE3Tz2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"**Large Language Model: A Revolutionary AI Technology**\n",
        "\n",
        "  A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and generate human-like language at an unprecedented scale. These models are trained on massive amounts of text data, allowing them to learn patterns, relationships, and nuances of language.\n",
        "\n",
        "  **Key Characteristics:**\n",
        "\n",
        "  1. **Scalability**: LLMs are trained on vast amounts of text data, often in the order of billions of parameters.\n",
        "  2. **Contextual understanding**: They can comprehend context, nuances, and subtleties of language, enabling more accurate and informative responses.\n",
        "  3. **Generative capabilities**: LLMs can generate coherent and natural-sounding text, making them useful for applications like chatbots, language translation, and content creation.\n",
        "  4. **Continuous learning**: These models can learn from new data and adapt to changing language patterns, ensuring they stay relevant and accurate over time.\n",
        "\n",
        "  **Applications:**\n",
        "\n",
        "  1. **Virtual assistants**: LLMs power virtual assistants like Siri, Alexa, and Google Assistant, enabling more natural and effective human-computer interaction.\n",
        "  2. **Language translation**: They facilitate accurate and efficient language translation, breaking language barriers and fostering global communication.\n",
        "  3. **Content creation**: LLMs can generate high-quality content, such as articles, stories, and even entire books.\n",
        "  4. **Chatbots and customer service**: They enable more sophisticated and empathetic chatbots, improving customer experiences and support.\n",
        "\n",
        "  **Future Implications:**\n",
        "\n",
        "  1. **Improved language understanding**: LLMs will continue to advance our understanding of language, enabling more effective human-AI collaboration.\n",
        "  2. **Increased automation**: They will automate tasks, freeing humans to focus on creative and high-value work.\n",
        "  3. **Enhanced decision-making**: LLMs will provide insights and analysis, supporting informed decision-making in various industries.\n",
        "\n",
        "  As LLMs continue to evolve, we can expect significant advancements in natural language processing, machine learning, and AI research, leading to transformative impacts on various aspects of our lives.\"\"\""
      ],
      "metadata": {
        "id": "0p2zh5WSI1pZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_text = summarizer(text,max_length=130,min_length=30,do_sample=False)[0][\"summary_text\"]\n",
        "summarized_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "1BGTm3apJnPu",
        "outputId": "395cfbda-7095-4218-d9b4-d44f809e9881"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A Large Language Model (LLM) is a type of artificial intelligence (AI) designed to process and generate human-like language at an unprecedented scale. These models are trained on massive amounts of text data, allowing them to learn patterns, relationships, and nuances of language. LLMs are useful for applications like chatbots, language translation, and content creation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2(summarized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILl5eB_9J9nx",
        "outputId": "fd61a435-1f43-4cc7-8cf4-199ccb3c0b63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'neutral', 'score': 0.8985012173652649},\n",
              "  {'label': 'approval', 'score': 0.10111037641763687},\n",
              "  {'label': 'realization', 'score': 0.02291891910135746},\n",
              "  {'label': 'admiration', 'score': 0.00703467708081007},\n",
              "  {'label': 'annoyance', 'score': 0.006183772813528776},\n",
              "  {'label': 'optimism', 'score': 0.003412934485822916},\n",
              "  {'label': 'disapproval', 'score': 0.002914941869676113},\n",
              "  {'label': 'disappointment', 'score': 0.0021586325019598007},\n",
              "  {'label': 'confusion', 'score': 0.0016497572651132941},\n",
              "  {'label': 'disgust', 'score': 0.0013805505586788058},\n",
              "  {'label': 'excitement', 'score': 0.00131756323389709},\n",
              "  {'label': 'joy', 'score': 0.0011456242064014077},\n",
              "  {'label': 'love', 'score': 0.000954504357650876},\n",
              "  {'label': 'amusement', 'score': 0.0008595519466325641},\n",
              "  {'label': 'desire', 'score': 0.00083174929022789},\n",
              "  {'label': 'curiosity', 'score': 0.0008109523914754391},\n",
              "  {'label': 'anger', 'score': 0.0007634891080670059},\n",
              "  {'label': 'caring', 'score': 0.0007537549827247858},\n",
              "  {'label': 'surprise', 'score': 0.0006980387261137366},\n",
              "  {'label': 'gratitude', 'score': 0.0006840504356659949},\n",
              "  {'label': 'sadness', 'score': 0.000674503156915307},\n",
              "  {'label': 'fear', 'score': 0.0005927868187427521},\n",
              "  {'label': 'relief', 'score': 0.0005660102469846606},\n",
              "  {'label': 'pride', 'score': 0.00046056174323894083},\n",
              "  {'label': 'embarrassment', 'score': 0.0003284414706286043},\n",
              "  {'label': 'nervousness', 'score': 0.00022482349595520645},\n",
              "  {'label': 'remorse', 'score': 0.00018773242481984198},\n",
              "  {'label': 'grief', 'score': 0.00016795851115603}]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversational"
      ],
      "metadata": {
        "id": "GLtA2gZGKeS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = pipeline(model = \"facebook/blenderbot-400M-distill\")"
      ],
      "metadata": {
        "id": "VtPT_61ZKb8J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = chatbot(\"Hii, Im Somendra, How are you?\")"
      ],
      "metadata": {
        "id": "B3HJbQGvKuXN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XVAPIpdK0xw",
        "outputId": "2298954b-8212-4a32-a261-6d572b38db7d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \" I'm doing well, thank you. How about yourself? What do you do for a living?\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = chatbot(\"Im a data science intern, what about you?\")\n",
        "conversation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCIi_dtZK2hu",
        "outputId": "f08d38f4-f383-4c9e-df0e-35b1fe6ce5bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \" I'm a computer programmer. What kind of work do you do as a data scientist?\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deplot Chatbot UI"
      ],
      "metadata": {
        "id": "KM2Wa3TWLeAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Sentiment Chatbot"
      ],
      "metadata": {
        "id": "poNjJRVtLiKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!pip install gradio"
      ],
      "metadata": {
        "id": "BukbehrtMb8j"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "XBlXKahwMW0r"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top3_text_classes(message,history):\n",
        "  return str(classifier2(message)[0][:3]).replace('}, {', '\\n').replace('[{', '').replace('}]', '')"
      ],
      "metadata": {
        "id": "1PcNmOHkLPs9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_sentiment = gr.ChatInterface(top3_text_classes,title = \"Text Sentiment Chatbot\",description = \"Ask me anything\")\n",
        "demo_sentiment.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "AKcygAKqOLus",
        "outputId": "cb940401-2f9c-4861-dfc3-4a6a7463dd76"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:228: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://55ce49caa0b7ce9cc7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://55ce49caa0b7ce9cc7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizer Chatbot"
      ],
      "metadata": {
        "id": "t08hwIVUPKY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarizer_bot(message,history):\n",
        "  return summarizer(message,max_length=130,min_length=30,do_sample=False)[0][\"summary_text\"]\n",
        "\n",
        "demo_summarizer = gr.ChatInterface(summarizer_bot,title = \"Summarizer Chatbot\",description = \"Ask me anything\")\n",
        "demo_summarizer.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "RBJIZ51eOjsy",
        "outputId": "7454626e-2d19-44c0-b829-58ebb817a705"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:228: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://956061a99cbf0d9fc4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://956061a99cbf0d9fc4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Chatbot"
      ],
      "metadata": {
        "id": "weTm-UvwQFCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message_list = []\n",
        "response_list = []\n",
        "\n",
        "def vanilla_chatbot(message,history):\n",
        "  conversation = chatbot(message)\n",
        "  return conversation[0]['generated_text']\n",
        "\n",
        "demo_vanilla = gr.ChatInterface(vanilla_chatbot,title = \"Vanilla Chatbot\",description = \"Ask me anything\")\n",
        "demo_vanilla.launch(share = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "AhKWoaNnPYKH",
        "outputId": "8511dc0c-dc78-44fd-8701-99e5398ae547"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:228: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9296c443700ebf3f4b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9296c443700ebf3f4b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OsbU6DpqQwsc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}